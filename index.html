<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Fanqi Wan's homepage</title>

  <meta name="author" content="Fanqi Wan">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Fanqi Wan (‰∏áÂá°Áê¶)</name>
              </p>
              <p>Hello! My name is Fanqi Wan, and I am a final-year MS student at Sun Yat-sen University, advised by <a href="https://sites.google.com/site/xiaojunquan/">Prof. Xiaojun Quan</a>. Before this, I received my Bachelor's degree from Xi'an Jiaotong University. Previously, I conducted my internship at Tencent AI Lab (2023.03-2024.05), ByteDance Seed (2024.06-2025.02), and Alibaba Tongyi (2025.03-now).
                </p>
              <p style="text-align:center">
                  <a href="mailto:fanqiwan2018@gmail.com">Email</a>  /
		  <a href="images/Fanqi_Wan_s_CV_ZH.pdf">CV</a>  /
                  <a href="https://scholar.google.com/citations?user=AeS1tmEAAAAJ&hl=zh-CN">Google Scholar</a>  /
		  <a href="https://www.semanticscholar.org/author/Fanqi-Wan/2217614543">Semantic Scholar</a>  /    
                  <a href="https://github.com/fanqiwan">GitHub</a>  /
		  <a href="https://huggingface.co/Wanfq">HF</a>  /
                  <a href="https://twitter.com/fanqiwan">X</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/fanqiwan.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/fanqiwan.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                My main research interests focused on deep learning for natural language generation. Previously, my work primarily focused on dialogue systems. After the emergence of large language models (LLMs), my research direction shifted towards LLM alignment (e.g., domain-specific LLMs, factual LLMs, self-improving LLMs, long-context LLMs, reasoning LLMs) and knowledge fusion (e.g., combining the strengths of LLMs with diverse structures/scales/functionarities). Representative papers are <span class="highlight">highlighted</span>.
              </p>
            </td>
          </tr>
        </tbody></table>


    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

    <tr>
      <td colspan="2" style="padding:20px;text-align:left;font-weight:bold;background-color:#ffffff;">
        Knowledge Fusion
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/fuseo1.png" alt="PontTuset" width="160" style="border-style: none">
      </td>
      <td width="75%" valign="middle">
        <a href="https://huggingface.co/blog/Wanfq/fuseo1-preview" id="conf_fuseo1">
          <papertitle><span class="highlight">FuseO1-Preview: System-II Reasoning Fusion of LLMs</span></papertitle>
        </a>
        <br>
        <strong>Fanqi Wan</strong>,
	Longguang Zhong,
	Ziyi Yang,
	Weizhou Shen,
	Xinting Huang
        <br>
        <em>Tech Report</em>, 2025
        <br>
        <a href="https://github.com/fanqiwan/FuseLLM">[GitHub]</a>
        /
	<a href="https://huggingface.co/collections/Wanfq/fuseo1-preview-678eb7c76c337bdf15edef4c">[HF]</a>
        /
        <a href="https://huggingface.co/blog/Wanfq/fuseo1-preview">[Paper]</a>
	/
	<a href="https://www.reddit.com/r/LocalLLaMA/comments/1i81pbk/this_merge_is_amazing/">[r/LocalLLaMA]</a>
	/
	<a href="https://github.com/arcee-ai/mergekit">[Mergekit Support]</a>
        <p></p>
        <p>FuseO1-Preview is our initial endeavor to enhance the System-II reasoning capabilities of large language models (LLMs) through innovative model fusion techniques. <strong>The resulted FuseO1-DeepSeekR1-QwQ-SkyT1-32B-Preview achieves a Pass@1 accuracy of 74.0 on AIME24, demonstrating significant performance improvements compared to the OpenAI o1-preview (44.6) and OpenAI o1-mini (63.4), even approaching OpenAI o1 (79.2)</strong>.</p>
      </td>
    </tr>
	    
    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/fusechat3.png" alt="PontTuset" width="160" style="border-style: none">
      </td>
      <td width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2503.04222" id="conf_fusechat3">
          <papertitle><span class="highlight">FuseChat-3.0: Preference Optimization Meets Heterogeneous Model Fusion</span></papertitle>
        </a>
        <br>
	Ziyi Yang,
        <strong>Fanqi Wan</strong>,
	Longguang Zhong,
	Canbing Huang,
	Guosheng Liang,
	Xiaojun Quan
        <br>
        <em>ICLR SCI-FM Workshop</em>, 2025
        <br>
        <a href="https://github.com/fanqiwan/FuseLLM">[GitHub]</a>
        /
	<a href="https://huggingface.co/collections/Wanfq/fusechat-30-675aab8d5b0522bba020b43c">[HF]</a>
        /
        <a href="https://arxiv.org/abs/2503.04222">[Paper]</a>
	/
	<a href="https://huggingface.co/papers/2503.04222">[HF Daily Papers]</a>
	/
	<a href="https://www.reddit.com/r/LocalLLaMA/comments/1hd22cq/fusechat30_preference_optimization_for_implicit/?rdt=45331">[r/LocalLLaMA]</a>
	/
	<a href="https://mp.weixin.qq.com/s/xI_GLkO0eskwayV_TveuUg">[È≠îÊê≠Á§æÂå∫]</a>
	/
	<a href="https://huggingface.co/blog/Wanfq/fusechat-3">[Blog]</a>
	/
	<a href="https://slit-ai.github.io/FuseChat-3.0">[Website]</a>
        <p></p>
        <p>We introduce FuseChat-3.0, a suite of large language models (LLMs) developed by integrating the strengths of heterogeneous source LLMs into more compact target LLMs. Using Llama-3.1-8B-Instruct as the target model, it demonstrates <strong>remarkable gains of 37.1 points and 30.1 points on AlpacaEval-2 and Arena-Hard</strong>, respectively.</p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/fuserl.png" alt="PontTuset" width="160" style="border-style: none">
      </td>
      <td width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2504.06562" id="conf_fuserl">
          <papertitle><span class="highlight">FuseRL: Dense Preference Optimization for Heterogeneous Model Fusion</span></papertitle>
        </a>
        <br>
	Longguang Zhong*,
        <strong>Fanqi Wan*</strong>,
	Ziyi Yang,
	Guosheng Liang,
	Tianyuan Shi,
	Xiaojun Quan
        <br>
        <em>Tech Report</em>, 2025
        <br>
        <a href="https://arxiv.org/abs/2504.06562">[Paper]</a>
        <p></p>
        <p>We propose FuseRL, a novel two-stage framework comprising FuseSFT and FusePO to maximize the utilization of source LLMs. Using Llama-3.1-8B-Instruct as the target model, our approach achieves <strong>state-of-the-art performance among 8B LLMs on AlpacaEval-2 and Arena-Hard</strong>.</p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/wrpo.png" alt="PontTuset" width="160" style="border-style: none">
      </td>
      <td width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2412.03187" id="conf_wrpo">
          <papertitle><span class="highlight">Weighted-Reward Preference Optimization for Implicit Model Fusion</span></papertitle>
        </a>
        <br>
	Ziyi Yang*,
        <strong>Fanqi Wan*</strong>,
	Longguang Zhong,
	Tianyuan Shi,
	Xiaojun Quan
        <br>
        <em>ICLR</em>, 2025
        <br>
        <a href="https://github.com/fanqiwan/FuseLLM">[GitHub]</a>
        /
	<a href="https://huggingface.co/collections/Wanfq/fusechat-30-675aab8d5b0522bba020b43c">[HF]</a>
        /
        <a href="https://arxiv.org/abs/2412.03187">[Paper]</a>
	/
	<a href="https://huggingface.co/papers?date=2024-12-05">[HF Daily Papers]</a>
        <p></p>
        <p>We propose Weighted-Reward Preference Optimization (WRPO), which leverages preference optimization between the source LLMs and the target LLM to transfer their capabilities effectively. WRPO achieves <strong>a LC Win Rate of 55.9% against GPT-4-Preview-1106 on AlpacaEval-2 and a Win Rate of 46.2% against GPT-4-0314 on Arena-Hard</strong>.</p>
      </td>
    </tr>
	
    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/fusechat.png" alt="PontTuset" width="160" style="border-style: none">
      </td>
      <td width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2408.07990" id="conf_fusechat">
          <papertitle><span class="highlight">FuseChat: Knowledge Fusion of Chat Models</span></papertitle>
        </a>
        <br>
        <strong>Fanqi Wan</strong>,
	Longguang Zhong,
	Ziyi Yang,
	Ruijun Chen,
	Xiaojun Quan
        <br>
        <em>Tech Report</em>, 2024
        <br>
        <a href="https://github.com/fanqiwan/FuseLLM">[GitHub]</a>
        /
	<a href="https://huggingface.co/collections/Wanfq/fusechat-20-66bf3462c55655c7152e4e23">[HF]</a>
        /
        <a href="https://arxiv.org/abs/2408.07990">[Paper]</a>
	/
        <a href="https://twitter.com/_akhaliq/status/1762344073820578145">[Featured by AK]</a>
	/
	<a href="https://huggingface.co/papers?date=2024-02-27">[HF Daily Papers]</a>
	/
        <a href="https://mp.weixin.qq.com/s/wD9uP33jTZX5jINadcn8IQ">[Êú∫Âô®‰πãÂøÉ]</a>
        <p></p>
        <p>We propose FuseChat, an extended framework of FuseLLM to integrate the collective knowledge and individual strengths of multiple structure- and scale-varied chat LLMs into a more powerful chat LLM. FuseChat-7B is <strong>comparable to the larger Mixtral-8x7B-Instruct and and approaches GPT-3.5-Turbo-1106</strong> on MT-Bench.</p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/profuser.png" alt="PontTuset" width="160" style="border-style: none">
      </td>
      <td width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2408.04998" id="conf_profuser">
          <papertitle>ProFuser: Progressive Fusion of Large Language Models</papertitle>
        </a>
        <br>
	Tianyuan Shi, 
	<strong>Fanqi Wan</strong>, 
	Canbin Huang, 
	Xiaojun Quan,
	Chenliang Li, 
	Ming Yan, 
	Ji Zhang
        <br>
        <em>Tech Report</em>, 2024
        <br>
        <a href="https://github.com/fanqiwan/FuseLLM">[GitHub]</a>
        /
	<a href="https://huggingface.co/collections/Wanfq/fusellm-65ad101d3022589371ff960e">[HF]</a>
        /
        <a href="https://arxiv.org/abs/2408.04998">[Paper]</a>
        <p></p>
        <p>We introduce a novel approach that enhances the fusion process by incorporating both the training and inference modes from multiple structurally diverse LLMs.</p>
      </td>
    </tr>
	    
    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/fusellm.png" alt="PontTuset" width="160" style="border-style: none">
      </td>
      <td width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2401.10491" id="conf_fusellm">
          <papertitle><span class="highlight">Knowledge Fusion of Large Language Models</span></papertitle>
        </a>
        <br>
        <strong>Fanqi Wan</strong>,
        Xinting Huang,
        Deng Cai,
        Xiaojun Quan,
        Wei Bi,
        Shuming Shi
        <br>
        <em>ICLR</em>, 2024
        <br>
        <a href="https://github.com/fanqiwan/FuseLLM">[GitHub]</a>
        /
	<a href="https://huggingface.co/collections/Wanfq/fusellm-65ad101d3022589371ff960e">[HF]</a>
        /
        <a href="https://arxiv.org/abs/2401.10491">[Paper]</a>
	/
        <a href="https://twitter.com/omarsar0/status/1749267663900057620">[Featured by elvis]</a>
	/
        <a href="https://twitter.com/ai_database/status/1749600484397363226">[Featured by AIDB]</a>
	/
        <a href="https://mp.weixin.qq.com/s/7JJBB_lNHKVoeaMtvCEyfQ">[Êú∫Âô®‰πãÂøÉ]</a>
        <p></p>
        <p>We propose FuseLLM to create a unified model that combines the distinctive strengths of multiple structurally diverse LLMs. FuseLLM-7B <strong>surpasses Llama-2-7B on 12 benchmarks</strong>, including commonsense, reasoning, question-answering, and code generation.</p>
      </td>
    </tr>

    <tr>
      <td colspan="2" style="padding:20px;text-align:left;font-weight:bold;background-color:#ffffff;">
        LLM Alignment
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/l1.png" alt="PontTuset" width="160" style="border-style: none">
      </td>
      <td width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2505.17667" id="conf_l1">
          <papertitle><span class="highlight">QwenLong-L1: Towards Long-Context Large Reasoning Models with Reinforcement Learning</span></papertitle>
        </a>
        <br>
	<strong>Fanqi Wan</strong>,
	Weizhou Shen,
	Shengyi Liao,
	Yingcheng Shi,
	Chenliang Li,
	Ziyi Yang,
	Ji Zhang,
	Fei Huang,
	Jingren Zhou,
	Ming Yan
        <br>
        <em>Tech Report</em>, 2025
        <br>
        <a href="https://github.com/Tongyi-Zhiwen/QwenLong-L1">[GitHub]</a>
        /
	<a href="https://huggingface.co/Tongyi-Zhiwen/QwenLong-L1-32B">[HF]</a>
        /
        <a href="https://arxiv.org/abs/2505.17667">[Paper]</a>
	/
	<a href="https://www.reddit.com/r/LocalLLaMA/comments/1kvnf46/comment/muau2ne/">[r/LocalLLaMA]</a>
	/
	<a href="https://huggingface.co/papers/2505.17667">[HF Daily Papers]</a>
        <p></p>
        <p>We propose QwenLong-L1, a framework that adapts short-context LRMs to long-context scenarios via progressive context scaling. <strong>QwenLong-L1-32B outperforms flagship LRMs like OpenAI-o3-mini and Qwen3-235B-A22B, achieving performance on par with Claude-3.7-Sonnet-Thinking</strong></p>
      </td>
    </tr>
	    
    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/solopo.png" alt="PontTuset" width="160" style="border-style: none">
      </td>
      <td width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2505.11166" id="conf_solopo">
          <papertitle>SoLoPO: Unlocking Long-Context Capabilities in LLMs via Short-to-Long Preference Optimization</papertitle>
        </a>
        <br>
	Huashan Sun, 
	Shengyi Liao, 
	Yansen Han, 
	Yu Bai, 
	Yang Gao, 
	Cheng Fu, 
	Weizhou Shen, 
	<strong>Fanqi Wan</strong>,
	Ming Yan, 
	Ji Zhang, 
	Fei Huang
        <br>
        <em>Tech Report</em>, 2025
        <br>
        <a href="https://arxiv.org/abs/2505.11166">[Paper]</a>
        <p></p>
        <p>We propose a framework named Short-to-Long Preference Optimization (SoLoPO), decoupling long-context preference optimization (PO) into two components: short-context PO and short-to-long reward alignment (SoLo-RA), supported by both theoretical and empirical evidence.</p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/mutual.png" alt="PontTuset" width="160" style="border-style: none">
      </td>
      <td width="75%" valign="middle">
        <a href="https://arxiv.org/abs/xxxx.xxxxx" id="conf_mutual">
          <papertitle>Mutual-Taught for Co-adapting Policy and Reward Models</papertitle>
        </a>
        <br>
	Tianyuan Shi,
	Canbin Huang, 
	<strong>Fanqi Wan</strong>,
	Longguang Zhong, 
	Ziyi Yang,
	Weizhou Shen, 
	Xiaojun Quan,
	Ming Yan
        <br>
        <em>ACL</em>, 2025
        <br>
        <a href="https://arxiv.org/abs/xxxx.xxxxx">[Paper]</a>
        <p></p>
        <p>we propose Mutual-Taught, a self-training method that iteratively improves both the policy model and reward model without requiring additional human annotation.</p>
      </td>
    </tr>	
	    
    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/ads.png" alt="PontTuset" width="160" style="border-style: none">
      </td>
      <td width="75%" valign="middle">
        <a href="https://openreview.net/pdf?id=5YCZZSEosw" id="conf_ads">
          <papertitle><span class="highlight">Let Large Languague Models Find the Data to Train Themselves</span></papertitle>
        </a>
        <br>
        <strong>Fanqi Wan</strong>,
        Deng Cai,
        Shijue Huang,
        Xiaojun Quan,
        Mingxuan Wang
        <br>
        <em>Tech Report</em>, 2025
        <br>
        <a href="https://openreview.net/pdf?id=5YCZZSEosw">[Paper]</a>
        <p></p>
        <p>We propose ADS, a self-improving framework where models can invoke APIs to crawl and/or generate tailored datasets from various resources and environments, and retrain themselves.</p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/adpa.png" alt="PontTuset" width="160" style="border-style: none">
      </td>
      <td width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2502.17927" id="conf_adpa">
          <papertitle><span class="highlight">Advantage-Guided Distillation for Preference Alignment in Small Language Models</span></papertitle>
        </a>
        <br>
	Shiping Gao, 
	<strong>Fanqi Wan</strong>,
	Jiajian Guo, 
	Xiaojun Quan, 
	Qifan Wang
        <br>
        <em>ICLR Spotlight</em>, 2025
        <br>
	<a href="https://github.com/SLIT-AI/ADPA">[GitHub]</a>
	/
	<a href="https://arxiv.org/abs/2502.17927">[Paper]</a>
	/
	<a href="https://mp.weixin.qq.com/s/tP_KoTZ8AiFYVk_ReNZ5Ug">[Paper Weekly]</a>
        <p></p>
        <p>We propose Advantage-Guided Distillation for Preference Alignment (ADPA), which leverages an advantage function from the aligned teacher to deliver more nuanced, distribution-level reward signals for the student's alignment.</p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/ske.png" alt="PontTuset" width="160" style="border-style: none">
      </td>
      <td width="75%" valign="middle">
        <a href="https://ojs.aaai.org/index.php/AAAI/article/view/34590" id="conf_ske">
          <papertitle>Empowering Self-Learning of LLMs: Inner Knowledge Explicitation as a Catalyst</papertitle>
        </a>
        <br>
	Shijue Huang,
	Wanjun Zhong,
	Deng Cai,
        <strong>Fanqi Wan</strong>,
        Chengyi Wang,
        Mingxuan Wang,
	Mu Qiao,
	Ruifeng Xu
        <br>
        <em>AAAI</em>, 2025
        <br>
        <a href="https://ojs.aaai.org/index.php/AAAI/article/view/34590">[Paper]</a>
        <p></p>
        <p>We introduces a Self Knowledge Explicitation Learning (SKE-Learn) framework, which equips the LLMs with meta-skills to explicitly extract, verify and utilize inner knowledge for reasoning.</p>
      </td>
    </tr>
	    
    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/seft.png" alt="PontTuset" width="160" style="border-style: none">
      </td>
      <td width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2406.10813" id="conf_seft">
          <papertitle>Self-Evolution Fine-Tuning for Policy Optimization</papertitle>
        </a>
        <br>
	Ruijun Chen, 
	Jiehao Liang, 
	Shiping Gao,
        <strong>Fanqi Wan</strong>,
        Xiaojun Quan
        <br>
        <em>EMNLP Findings</em>, 2024
        <br>
        <a href="https://arxiv.org/abs/2406.10813">[Paper]</a>
        <p></p>
        <p>We introduce self-evolution fine-tuning for policy optimization, which eliminates the need for annotated data samples during alignment.</p>
      </td>
    </tr>
	    
    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/kca.png" alt="PontTuset" width="160" style="border-style: none">
      </td>
      <td width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2401.10768" id="conf_kca">
          <papertitle><span class="highlight">Knowledge Verification to Nip Hallucination in the Bud</span></papertitle>
        </a>
        <br>
        <strong>Fanqi Wan</strong>,
        Xinting Huang,
        Leyang Cui,
        Xiaojun Quan,
        Wei Bi,
        Shuming Shi
        <br>
        <em>EMNLP</em>, 2024
        <br>
        <a href="https://github.com/fanqiwan/KCA">[GitHub]</a>
	/
	<a href="https://huggingface.co/collections/Wanfq/kca-65aa9ab25c84d7d5e7c9d0da">[HF]</a>
        /
        <a href="https://arxiv.org/abs/2401.10768">[Paper]</a>
        <p></p>
        <p>We introduce Knowledge Consistent Alignment to <strong>verify and minimize the knowledge inconsistency</strong> between external knowledge in the alignment data and the intrinsic knowledge embedded in foundation LLMs, thus mitigating hallucinations before alignment.</p>
      </td>
    </tr>
	    
    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/explore_instruct.png" alt="PontTuset" width="160" style="border-style: none">
      </td>
      <td width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2310.09168" id="conf_explore-instruct">
          <papertitle><span class="highlight">Explore-Instruct: Enhancing Domain-Specific Instruction Coverage through Active Exploration</span></papertitle>
        </a>
        <br>
        <strong>Fanqi Wan</strong>,
        Xinting Huang,
        Tao Yang,
        Xiaojun Quan,
        Wei Bi,
        Shuming Shi
        <br>
        <em>EMNLP</em>, 2023
        <br>
        <a href="https://github.com/fanqiwan/Explore-Instruct">[GitHub]</a>
	/
	<a href="https://huggingface.co/collections/Wanfq/explore-instruct-65280973f74b8bf3e9f9bd7e">[HF]</a>
        /
        <a href="https://arxiv.org/abs/2310.09168">[Paper]</a>
	/
        <a href="https://mp.weixin.qq.com/s/rDw8avX2pfe2T9xBDs9NGQ">[Paper Weekly]</a>
        <p></p>
        <p>We propose a novel approach to enhance the domain-specific instruction coverage by utilizing LLMs to explore the domain space from both breadth and depth automatically. Explore-Instruct <strong>outperforms Self-Instruct in three specific domains</strong>.</p>
      </td>
    </tr>

    <tr>
      <td colspan="2" style="padding:20px;text-align:left;font-weight:bold;background-color:#ffffff;">
        Dialogue Systems
      </td>
    </tr>
	    
    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/mk_tod.png" alt="PontTuset" width="160" style="border-style: none">
      </td>
      <td width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2310.08877" id="conf_mk-tod">
          <papertitle>Retrieval-Generation Alignment for End-to-End Task-Oriented Dialogue System</papertitle>
        </a>
        <br>
        Weizhou Shen,
        Yingqi Gao,
        Canbin Huang,
        <strong>Fanqi Wan</strong>,
        Xiaojun Quan,
        Wei Bi
        <br>
        <em>EMNLP</em>, 2023
        <br>
        <a href="https://github.com/shenwzh3/MK-TOD">[GitHub]</a>
        /
        <a href="https://arxiv.org/abs/2310.08877">[Paper]</a>
        <p></p>
        <p>We introduce maximal marginal likelihood for retriever training to address the retrieval-generation misalignment in end-to-end task-oriented dialogue systems.</p>
      </td>    
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/maker.png" alt="PontTuset" width="160" style="border-style: none">
      </td>
      <td width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2305.10149" id="conf_maker">
          <papertitle><span class="highlight">Multi-Grained Knowledge Retrieval for End-to-End Task-Oriented Dialog</span></papertitle>
        </a>
        <br>
        <strong>Fanqi Wan</strong>,
        Weizhou Shen,
        Ke Yang,
        Xiaojun Quan,
        Wei Bi
        <br>
        <em>ACL</em>, 2023
        <br>
        <a href="https://github.com/18907305772/MAKER">[GitHub]</a>
	/
	<a href="https://huggingface.co/collections/Wanfq/maker-6527fde2a4be83259cdfc9e9">[HF]</a>
        /
        <a href="https://arxiv.org/abs/2305.10149">[Paper]</a>
        <p></p>
        <p>We propose a multi-grained knowledge retriever and introduce a novel distillation objective for retriever training. MAKER achieves <strong>SOTA performance on MultiWOZ 2.1 and CamRest</strong> with both condensed KB and full KB.</p>
      </td>    
    </tr>

    <tr>
      <td colspan="2" style="padding:20px;text-align:left;font-weight:bold;background-color:#ffffff;">
        Misc.
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/cprs.png" alt="PontTuset" width="160" style="border-style: none">
      </td>
      <td width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2505.18092" id="conf_cprs">
          <papertitle>QwenLong-CPRS: Towards ‚àû-LLMs with Dynamic Context Optimization</papertitle>
        </a>
        <br>
	Weizhou Shen, 
	Chenliang Li, 
	<strong>Fanqi Wan</strong>,
	Shengyi Liao, 
	Shaopeng Lai, 
	Bo Zhang, 
	Yingcheng Shi, 
	Yuning Wu, 
	Gang Fu, 
	Zhansheng Li, 
	Bin Yang, 
	Ji Zhang, 
	Fei Huang, 
	Jingren Zhou,
	Ming Yan
        <br>
        <em>Tech Report</em>, 2025
        <br>
        <a href="https://github.com/Tongyi-Zhiwen/QwenLong-CPRS">[GitHub]</a>
        /
	<a href="https://huggingface.co/Tongyi-Zhiwen/QwenLong-CPRS-7B">[HF]</a>
        /
        <a href="https://arxiv.org/abs/2505.18092">[Paper]</a>
        <p></p>
        <p>We propose QwenLong-CPRS, which implemented through a novel dynamic context optimization mechanism to enable multi-granularity context compression guided by natural language instructions, achieving both efficiency gains and improved performance.</p>
      </td>    
    </tr>    
	    
    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/blockpruner.png" alt="PontTuset" width="160" style="border-style: none">
      </td>
      <td width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2406.10594" id="conf_blockpruner">
          <papertitle>BlockPruner: Fine-grained Pruning for Large Language Models</papertitle>
        </a>
        <br>
	Longguang Zhong,
        <strong>Fanqi Wan</strong>,
	Ruijun Chen,
        Xiaojun Quan,
	Liangzhi Li
        <br>
        <em>ACL Findings</em>, 2025
        <br>
        <a href="https://github.com/MrGGLS/BlockPruner">[GitHub]</a>
        /
        <a href="https://arxiv.org/abs/2406.10594">[Paper]</a>
        <p></p>
        <p>We propose a training-free structured pruning approach for fine-grained LLMs pruning.</p>
      </td>    
    </tr>    
	    
    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/psycot.png" alt="PontTuset" width="160" style="border-style: none">
      </td>
      <td width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2310.20256" id="conf_psycot">
          <papertitle>PsyCoT: Psychological Questionnaire as Powerful Chain-of-Thought for Personality Detection</papertitle>
        </a>
        <br>
        Tao Yang,
        Tianyuan Shi,
        <strong>Fanqi Wan</strong>,
        Xiaojun Quan,
        Qifan Wang,
        Bingzhe Wu,
        Jiaxiang Wu
        <br>
        <em>EMNLP Findings</em>, 2023
        <br>
        <a href="https://github.com/TaoYang225/PsyCoT">[GitHub]</a>
        /
        <a href="https://arxiv.org/abs/2310.20256">[Paper]</a>
        <p></p>
        <p>We propose a novel method for zero-shot personality detection in a multi-turn dialogue manner.</p>
      </td>    
    </tr>
	    
    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/clusterns.png" alt="PontTuset" width="160" style="border-style: none">
      </td>
      <td width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2305.09892" id="conf_clusterns">
          <papertitle>Clustering-Aware Negative Sampling for Unsupervised Sentence Representation</papertitle>
        </a>
        <br>
        Jinghao Deng,
        <strong>Fanqi Wan</strong>,
        Tao Yang,
        Xiaojun Quan,
        Rui Wang
        <br>
        <em>ACL Findings</em>, 2023
        <br>
        <a href="https://github.com/djz233/clusterns">[GitHub]</a>
        /
        <a href="https://arxiv.org/abs/2305.09892">[Paper]</a>
        <p></p>
        <p>We propose a novel method that incorporates cluster information into contrastive learning for unsupervised sentence representation learning.</p>
      </td>
    </tr>


    </tbody></table>


    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
      <td style="padding:20px;width:100%;vertical-align:middle">
        <heading>Education</heading>
        <p>
          MS Student in Computer Science, <strong>Sun Yat-sen University</strong> (2022.9-now).
        </p>
        <p>
          Bachelor of Automation, <strong>Xi'an Jiaotong University</strong> (2018.9-2022.6).
        </p>
      </td>
    </tr>
    </tbody></table>


    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
      <td style="padding:20px;width:100%;vertical-align:middle">
        <heading>Experience</heading>
        <p>
          Research Intern at NLP, <strong>Alibaba Tongyi</strong>, supervised by Dr. Ming Yan. (2025.3-now).
        </p>
	<p>
          Research Intern at Horizon, <strong>ByteDance Seed</strong>, supervised by Dr. Deng Cai. (2024.6-2025.2).
        </p>
	<p>
          Research Intern at NLPC, <strong>Tencent AI Lab</strong>, supervised by Dr. Xinting Huang and Dr. Wei Bi. (2023.3-2024.5).
        </p>
	<p>
          Commercial Projects on E-Commerce Platforms, <strong>Vipshop</strong>, supervised by Dr. Rui Wang. (2022.4-2023.1).
        </p>
      </td>
    </tr>
    </tbody></table>


    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
      <td style="padding:20px;width:100%;vertical-align:middle">
        <heading>Academic Competitions</heading>
        <p>
          <strong>2nd Prize</strong> on 2023 Xingzhi Cup Deep Learning Model Interpretability Task. (<strong>Team Leader</strong>) <a href="http://www.aiinnovation.com.cn/#/trackDetail?id=23">[Task]</a>
        </p>
        <p>
          <strong>2nd Prize</strong> on 2022 IFLYTEK AI Developer Competition Paper Abstracts Classification Task. (<strong>Team Leader</strong>) <a href="https://challenge.xfyun.cn/topic/info?type=abstract&option=phb">[Task]</a>
        </p>
        <p>
          <strong>3nd Prize</strong> on 2022 Ali Lingjie E-commerce Search Algorithm Competition. (<strong>Team Leader</strong>) <a href="https://tianchi.aliyun.com/specials/promotion/opensearch">[Task]</a>
        </p>
      </td>
    </tr>
    </tbody></table>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
      <td style="padding:20px;width:100%;vertical-align:middle">
        <heading>Academic Services</heading>
	<p>
	  <strong>NeurIPS Reviewer</strong>, 2024-.
	</p>
	<p>
          <strong>ICLR Reviewer</strong>, 2025-.
        </p>
        <p>
          <strong>AISTATS Reviewer</strong>, 2025-.
        </p>
	<p>
          <strong>ACL ARR Reviewer</strong>, 2025-.
        </p>
      </td>
    </tr>
    </tbody></table>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
      <td style="padding:20px;width:100%;vertical-align:middle">
        <heading>Selected Awards</heading>
	<p>
	  <strong>National Scholarship</strong>, Sun Yat-sen University, 2023.
	</p>
	<p>
          <strong>Outstanding Award for Tencent AI Lab Rhino-Bird Focused Research Program</strong>, Tencent, 2023.
        </p>
        <p>
          <strong>Excellent Graduate Students</strong>, Xi'an Jiaotong University, 2022.
        </p>
        <p>
          <strong>National Scholarship</strong>, Xi'an Jiaotong University, 2018.
        </p>
      </td>
    </tr>
    </tbody></table>

<!--  </tbody></table>-->

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr>
      <td style="padding:0px">
        <br>
        <p style="text-align:right;font-size:small;">
          Website's code is from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
          
        </p>
      </td>
    </tr>
  </tbody></table>
</td>
</tr>
  </tbody></table>
</body>

</html>
